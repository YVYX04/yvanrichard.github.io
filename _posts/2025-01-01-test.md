---
title: Predicting Delays in SBB Transportation Network
subtitle: SBB (Schweizerische Bundesbahnen) is Switzerland’s main railway operator and a widely recognised national institution. Switzerland is renowned for its Swiss Made quality, a standard that SBB actively upholds by striving for exceptional punctuality and high-quality passenger service. In this post, I aim to understand what make the strength of this giant by developing a full ML pipeline to predict delay.
layout: default
date: 2025-12-07
keywords: machine learning, logistic regression, random forest, SBB, trains, economics
published: true
---

# Foreword

The purpose of this blog post is to develop a small ML pipeline to demonstrate how small study projects like mine can be implemented. The precision and quality of my ML project is therefore secondary but will still be considered seriously.

# 1. The Machine Learning Pipeline

In their examination of machine learning workflows at varying scales, Biswas et al. (2022) outline how pipeline structures evolve according to operational requirements. In a professional, production-oriented setting, a fully integrated pipeline typically follows the structure shown below:

<div class='figure'>
    <img src="{{ '/images/DS_pipeline01.png' | relative_url }}" alt="Data pipeline"
         style="width: 100%; display: block; margin: 0 auto;" id = "fig1"/>
    <div class='caption'>
        <span class='caption-label'>Figure 1.</span> Concepts in a data science pipeline. The sub-tasks are listed below each stage. The stages are connected with feedback loops denoted with arrows. Solid arrows are always present in the lifecycle, while the dashed arrows are optional. Distant feedback loops (e.g.,from deployment to data acquisition) are also possible through intermediate stage(s).
    </div>
</div>

Naturally, the structure of a pipeline depends on the scope, constraints, and objectives of the project. **Figure 1** presents a highly comprehensive design that suits large–scale production environments but exceeds what is necessary for exploratory research. For this smaller-scale study, the pipeline is intentionally streamlined to focus on the essential components:

1. Data and Libraries Loading  
2. Exploratory Data Analysis (EDA)  
3. Data Cleaning and Preparation  
4. Feature Engineering  
5. Modeling Stage I  
6. Training and Evaluation  
7. Modeling Stage II (Hyper-parameter Tuning)  
8. Final Predictions  
9. Results and Interpretation  

While the overall structure draws inspiration from the framework presented above, several components are omitted as they are not required in the context of this project. Without further ado, let's dive in the first step!

# 3. Exploratory Data Analysis (EDA)

This stage helps us gain a clearer understanding of the dataset’s structure and content. As Behrens (1997, p. 132) states, “the goal of EDA is to discover patterns in data […] until a plausible story of the data is apparent.” In the context of a machine learning project, this is precisely the purpose EDA serves. By examining distributions, interactions, and variability within the data, we build knowledge that shapes the steps that follow. Data cleaning becomes more targeted, allowing decisions about handling missing values to be made with greater justification. Similarly, insights uncovered during EDA inform feature engineering, enabling the creation of features that better account for variance in the target. Ultimately, the strength of our predictions is closely tied to the depth of understanding achieved during this exploratory phase and our ability to translate those findings into meaningful model improvements.


`last updated on Sun. Dec. 21 at 12:19 CET`


## References

- Behrens, J. T. (1997). Principles and procedures of exploratory data analysis. *Psychological methods*, 2(2), 131.

- Biswas, S., Wardat, M., & Rajan, H. (2022). The art and practice of data science pipelines: A comprehensive study of data science pipelines in theory, in-the-small, and in-the-large. In *Proceedings of the 44th International Conference on Software Engineering* (pp. 2091-2103).



